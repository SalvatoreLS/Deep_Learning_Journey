{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gesture Recognition using YOLO algorithm\n",
        "In this notebook you can see the code I used to train my Gesture Recognition Algorithm."
      ],
      "metadata": {
        "id": "rH2Apw0xz8lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "KvQnlgp3-15h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir4O5OzV-Sfw"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcO7WPcQ_yYI",
        "outputId": "3badede2-ac9b-4794-c663-0f420e4f4122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract file\n",
        "I used `ZipFile` to easily extract data and provide the `data.yaml` file to the model."
      ],
      "metadata": {
        "id": "E1MbCcjc0KGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile(\"/content/drive/MyDrive//GestureRecognition_1.v3i.yolov8.zip\", 'r') as zObject:\n",
        "    zObject.extractall(\n",
        "        path=\"/content/dataset\")"
      ],
      "metadata": {
        "id": "TDh2YySUzg-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained model\n",
        "I am using YOLOv8n, because it is a good compromise.\n",
        "Despite being a small model, it can show impressive performamce in many cases."
      ],
      "metadata": {
        "id": "I2h6byUE0fBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "zcWg5bB2-zI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64abc9ac-1e51-473b-ff01-12e583ee641d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 79.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "To make the training more stable, I have chosen a batch size of 128 and low initial learning rate of 0.0001."
      ],
      "metadata": {
        "id": "u-OUhGXk04Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(\n",
        "    data='/content/dataset/data.yaml',\n",
        "    epochs=200,\n",
        "    imgsz=640,\n",
        "    batch=128,\n",
        "    workers=4,\n",
        "    lr0=0.0001,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "PGo4Acjn-xuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B93j3APq-uQ6",
        "outputId": "71e07190-c24f-4454-bcb7-1f3f22262a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.96 ðŸš€ Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/progettiAI/GestureRecognition/version5.yolov8/valid/labels.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         94         95      0.934      0.869      0.962      0.815\n",
            "                     C          9          9      0.992      0.889      0.895      0.771\n",
            "                  Fist          8          8          1      0.667      0.995      0.785\n",
            "                  Five          9          9      0.873          1      0.995      0.861\n",
            "                  Four          8          8          1      0.631      0.995      0.887\n",
            "                 Horns         11         11      0.823      0.909      0.915      0.742\n",
            "                   One         12         12       0.85      0.917      0.977        0.8\n",
            "                Others          1          1      0.849          1      0.995      0.895\n",
            "                 Three         11         11          1       0.93      0.995      0.876\n",
            "                 Thumb          7          7          1      0.675       0.87      0.664\n",
            "                   Two         11         11      0.912      0.939       0.95      0.794\n",
            "                  Zero          8          8      0.977          1      0.995      0.884\n",
            "Speed: 0.3ms preprocess, 7.0ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('yolov8_transfer_learning_v3.pt')"
      ],
      "metadata": {
        "id": "3WlfWLhw-vtj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}