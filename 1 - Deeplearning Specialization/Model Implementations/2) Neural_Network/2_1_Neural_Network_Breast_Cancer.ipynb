{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Network\n",
        "In this notebook I will implement a simple neural network with a single hidden layer with 10 neurons.\n",
        "\n"
      ],
      "metadata": {
        "id": "1CTsFR9pBWka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "mls1jhP3gwry"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "In this notebook, I will use the **Breast Cancer Wisconsin (Diagnostic) dataset** from **sklearn** to build a model for identifying malignant breast cancer. The goal is to train and evaluate a machine learning model for accurate diagnosis."
      ],
      "metadata": {
        "id": "Co-BE8VkBurP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "Y = Y.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "iOZ-y8dEhenk"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "KVWZDBZcr7BU"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "qEPj-tuc0vTc"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train_scaled.T\n",
        "X_test_scaled = X_test_scaled.T\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T"
      ],
      "metadata": {
        "id": "wYD6tSLc0QnS"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcOJxFteH0GV",
        "outputId": "6b999bc1-a0a9-40bf-a66e-bebbe73f7805"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 455) (1, 455)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_x = X_train_scaled.shape[0]  # number of features\n",
        "n_h = 10  # number of hidden units\n",
        "n_y = y_train.shape[0]   # binary classification"
      ],
      "metadata": {
        "id": "NY91xpy41NDL"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network model\n",
        "I wrote down a simple neural network with these functions:\n",
        "- `__init__`: executed when the model is initialized. It sets parameters with their starting values (randomly).\n",
        "- `forward_propagation`: It calculates those parameters that will be useful for calculating cost function.\n",
        "  $$z^{[1]} = w^{[1]}X + b^{[1]} \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: A^{[1]} = g^{[1]}(z^{[1]})$$\n",
        "  $$z^{[2]} = w^{[2]}A^{[1]} + b^{[2]} \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: A^{[2]} = g^{[2]}(z^{[2]}) = \\sigma(z^{[2]})$$\n",
        "- `compute_cost`: it calculates the cost function as follows:\n",
        "  $$\\mathcal{J}(w^{[1]}, b^{[1]}, w^{[2]}, b^{[2]}) = \\frac{1}{m}\\sum_{i=1}^m \\mathcal{L}(\\hat{y} - y)$$\n",
        "- `backward_propagation`: finds the derivatives of our parameters.\n",
        "  $$dz^{[2]} = A^{[2]} - Y$$\n",
        "  $$dw^{[2]} = \\frac{1}{m}dz^{[2]}A^{[2]T}$$\n",
        "  $$db^{[2]} = \\frac{1}{m}\\cdot np.sum(dz^{[2]}, axis=1, keepdims=True)$$\n",
        "  $$dz^{[1]} = w^{[2]T}dz^{[2]} \\star g'^{[1]}(z^{[1]})$$\n",
        "  where $\\star$ represents element-wise product.\n",
        "\n",
        "  I am using a $\\tanh$ activation function for the hidden layer and a sigmoid function for the output layer.\n",
        "  $$a = \\tanh(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$$\n",
        "  $$\\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
        "- `update_parameters`: it calculates the following equations:\n",
        "  $$w^{[1]} := w^{[1]} - \\alpha \\cdot dw^{[1]} \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: b^{[1]} := b^{[1]} - \\alpha \\cdot db^{[1]}$$\n",
        "  $$w^{[2]} := w^{[2]} - \\alpha \\cdot dw^{[2]} \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: b^{[2]} := b^{[2]} - \\alpha \\cdot db^{[2]}$$\n",
        "  where $Î±$ represents the learning rate.\n",
        "- `fit`: it performs the training of the network by using the previous functions.\n",
        "- `predict` and `score`: to make the model predict labels and evaluate its performance.\n",
        "\n",
        "**Note**: We don't initialize parameters with zero values because in that case the activation for each node will be the same, for each node of the hidden layer. This would generate symmetry, rendering the hidden layer be useless.\n",
        "Moreover we choose small values because in this way we avoid to have big values, in order to avoid the slope of the activation function be too close to zero, slowing down the gradient descent and so the learning of the network."
      ],
      "metadata": {
        "id": "kUeyRuQpDI0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork():\n",
        "\n",
        "  def __init__(self, n_x, n_h, n_y, num_iterations = 10000, learning_rate = 1.2, print_cost=False):\n",
        "\n",
        "    np.random.seed(2)\n",
        "\n",
        "    self.cost = 0.0\n",
        "\n",
        "    self.num_iterations = num_iterations\n",
        "    self.learning_rate = learning_rate\n",
        "    self.print_cost = print_cost\n",
        "\n",
        "    self.parameters = {\"W1\": np.random.randn(n_h, n_x)*0.01,\n",
        "                       \"W2\": np.random.randn(n_y, n_h)*0.01,\n",
        "                       \"b1\": np.zeros((n_h, 1)),\n",
        "                       \"b2\": np.zeros((n_y, 1))}\n",
        "\n",
        "    self.grads = {\"dW1\": 0.0,\n",
        "                  \"dW2\": 0.0,\n",
        "                  \"db1\": 0.0,\n",
        "                  \"db2\": 0.0}\n",
        "\n",
        "    self.cache = {\"Z1\": 0.0,\n",
        "                  \"Z2\": 0.0,\n",
        "                  \"A1\": 0.0,\n",
        "                  \"A2\": 0.0}\n",
        "\n",
        "  def sigmoid(self, Z):\n",
        "    s = 1 / (1 + np.exp(-Z))\n",
        "    return s\n",
        "\n",
        "\n",
        "  def forward_propagation(self, X):\n",
        "\n",
        "    Z1 = np.dot(self.parameters[\"W1\"], X) + self.parameters[\"b1\"]\n",
        "    A1 = np.tanh(Z1)\n",
        "    Z2 = np.dot(self.parameters[\"W2\"], A1) + self.parameters[\"b2\"]\n",
        "    A2 = self.sigmoid(Z2)\n",
        "\n",
        "    self.cache = {\"Z1\": Z1,\n",
        "                  \"Z2\": Z2,\n",
        "                  \"A1\": A1,\n",
        "                  \"A2\": A2}\n",
        "\n",
        "\n",
        "  def compute_cost(self, Y):\n",
        "\n",
        "    m = Y.shape[1]\n",
        "\n",
        "    logprobs = np.multiply(np.log(self.cache[\"A2\"]), Y) + np.multiply(1 - Y, np.log(1 - self.cache[\"A2\"]))\n",
        "    cost = - (1/m) * np.sum(logprobs)\n",
        "\n",
        "    self.cost = float(np.squeeze(cost))\n",
        "\n",
        "\n",
        "  def backward_propagation(self, X, Y):\n",
        "\n",
        "    m = X.shape[1]\n",
        "\n",
        "    dZ2 = self.cache[\"A2\"] - Y\n",
        "    dW2 = (1/m) * np.dot(dZ2, self.cache[\"A1\"].T)\n",
        "    db2 = (1/m) *(np.sum(dZ2, axis=1, keepdims=True))\n",
        "    dZ1 = np.dot(self.parameters[\"W2\"].T, dZ2) * (1 - np.power(self.cache[\"A1\"], 2))\n",
        "    dW1 = (1/m) *(np.dot(dZ1, X.T))\n",
        "    db1 = (1/m) *(np.sum(dZ1, axis=1, keepdims=True))\n",
        "\n",
        "    self.grads = {\"dW1\": dW1,\n",
        "          \"db1\": db1,\n",
        "          \"dW2\": dW2,\n",
        "          \"db2\": db2}\n",
        "\n",
        "\n",
        "  def update_parameters(self):\n",
        "\n",
        "    self.parameters[\"W1\"] -= self.learning_rate * self.grads[\"dW1\"]\n",
        "    self.parameters[\"W2\"] -= self.learning_rate * self.grads[\"dW2\"]\n",
        "    self.parameters[\"b1\"] -= self.learning_rate * self.grads[\"db1\"]\n",
        "    self.parameters[\"b2\"] -= self.learning_rate * self.grads[\"db2\"]\n",
        "\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "\n",
        "    costs = []\n",
        "\n",
        "    for i in range(0, self.num_iterations + 1):\n",
        "\n",
        "      self.forward_propagation(X)\n",
        "      self.compute_cost(Y)\n",
        "      costs.append(self.cost)\n",
        "      self.backward_propagation(X, Y)\n",
        "      self.update_parameters()\n",
        "\n",
        "      if self.print_cost and i % 1000 == 0:\n",
        "        print(\"Cost after iteration %i: %f\" %(i, self.cost))\n",
        "\n",
        "    sns.lineplot(costs)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "\n",
        "    self.forward_propagation(X)\n",
        "    predictions = (self.cache[\"A2\"] > 0.5)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "  def score(self, X, Y):\n",
        "\n",
        "    Y_pred = self.predict(X)\n",
        "    return np.mean(Y_pred == Y)\n",
        "\n"
      ],
      "metadata": {
        "id": "oidqr8dUh_u3"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Justification for Learning Rate of 2.5\n",
        "\n",
        "While a learning rate of 2.5 is unusually high, it has proven effective in this specific case:\n",
        "\n",
        "1. **Empirical success**: Fast convergence and good final performance observed.\n",
        "2. **Simple architecture**: Our one-hidden-layer network may tolerate larger update steps.\n",
        "3. **Efficiency**: Faster training with fewer iterations."
      ],
      "metadata": {
        "id": "uzo3juO_Ljiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = NeuralNetwork(n_x= n_x, n_h = 4, n_y = n_y, num_iterations = 10000, learning_rate = 2.5, print_cost=True)"
      ],
      "metadata": {
        "id": "u5xx2HNZxnxP"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model.fit(X = X_train_scaled, Y = y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "5lz0wC_NyLMn",
        "outputId": "9652bf78-6538-493f-e1f3-ed5be01f83f0"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.693501\n",
            "Cost after iteration 1000: 0.001744\n",
            "Cost after iteration 2000: 0.000696\n",
            "Cost after iteration 3000: 0.000427\n",
            "Cost after iteration 4000: 0.000307\n",
            "Cost after iteration 5000: 0.000238\n",
            "Cost after iteration 6000: 0.000194\n",
            "Cost after iteration 7000: 0.000164\n",
            "Cost after iteration 8000: 0.000142\n",
            "Cost after iteration 9000: 0.000125\n",
            "Cost after iteration 10000: 0.000111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArsUlEQVR4nO3df3RU9Z3/8dfMJDMhQhIgMoEQjAoVESQ0MTH+7nHabJe22u260S+VbKp0q2SLzdZqaoWtrQ5Vy7Jrs6ZSqT3+KJSuP7pKo5xRatFoNIiCIOqiJooToEgGAyYw8/n+IRkYSZCBJJ8k9/k45x4y937uve/7oZJX73zu57qMMUYAAACWuG0XAAAAnI0wAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMCqFNsFHI1YLKatW7dqxIgRcrlctssBAABHwRij3bt3a9y4cXK7e77/MSjCyNatW5WXl2e7DAAAcAxaWlo0fvz4HrcPijAyYsQISZ9eTEZGhuVqAADA0YhEIsrLy4v/Hu/JoAgjXV/NZGRkEEYAABhkPm+IBQNYAQCAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGDVMYWR2tpa5efnKy0tTSUlJWpsbOyx7UUXXSSXy3XYMnPmzGMuGgAADB1Jh5Hly5erurpaCxYs0Nq1azV9+nSVlZVp27Zt3bZ/+OGH9eGHH8aXDRs2yOPx6LLLLjvu4gEAwOCXdBhZtGiR5syZo8rKSk2ZMkV1dXVKT0/X0qVLu20/atQo5eTkxJdVq1YpPT2dMAIAACQlGUY6OzvV1NSkQCBw8AButwKBgBoaGo7qGPfee68uv/xynXDCCT226ejoUCQSSVgAAMDQlFQY2bFjh6LRqPx+f8J6v9+vcDj8ufs3NjZqw4YNuvrqq4/YLhgMKjMzM77wkjwAAIaufn2a5t5779W0adNUXFx8xHY1NTVqa2uLLy0tLf1UIQAA6G9JvSgvOztbHo9Hra2tCetbW1uVk5NzxH3b29u1bNky3XLLLZ97Hp/PJ5/Pl0xpx+TeNe+oZeceXV6cp8k5vIAPAAAbkroz4vV6VVhYqFAoFF8Xi8UUCoVUWlp6xH1XrFihjo4Offvb3z62SvvA469t1X3Pv6vmv+2xXQoAAI6V1J0RSaqurlZFRYWKiopUXFysxYsXq729XZWVlZKk2bNnKzc3V8FgMGG/e++9V5deeqlGjx7dO5X3AveBVxoby3UAAOBkSYeR8vJybd++XfPnz1c4HFZBQYHq6+vjg1qbm5vldifecNm8ebPWrFmjp556qneq7iWuA38aQxwBAMCWpMOIJFVVVamqqqrbbatXrz5s3WmnnTYgf+EfuDGiAVgaAACO4eh307jE1zQAANjm6DAi7owAAGCdo8OIuyuMcG8EAABrHB1Gur6miZFFAACwxtlhJP41DWkEAABbCCMAAMAqZ4eRrqdpuDECAIA1zg4jDGAFAMA6h4eRAwNYY5YLAQDAwZwdRg78yX0RAADscXYY4WkaAACsc3YYOfAnUQQAAHucHUYOjmAFAACWODqMMB08AAD2OTqMiOngAQCwztFhxMVbewEAsM7ZYcR2AQAAwNlhBAAA2EcYAQAAVhFGxNM0AADY5Ogw4mLQCAAA1jk6jAAAAPsIIwAAwCrCiJhnBAAAmxwdRlzMNAIAgHWODiMAAMA+wggAALCKMCIxywgAABY5OowwzwgAAPY5OowAAAD7CCMAAMAqwojERCMAAFjk6DDCmBEAAOxzdBgBAAD2EUYAAIBVhBExzwgAADY5OozwbhoAAOxzdBgBAAD2HVMYqa2tVX5+vtLS0lRSUqLGxsYjtt+1a5fmzp2rsWPHyufz6Qtf+IJWrlx5TAX3BZ7sBQDAnpRkd1i+fLmqq6tVV1enkpISLV68WGVlZdq8ebPGjBlzWPvOzk59+ctf1pgxY/THP/5Rubm5eu+995SVldUb9QMAgEEu6TCyaNEizZkzR5WVlZKkuro6PfHEE1q6dKluvPHGw9ovXbpUO3fu1PPPP6/U1FRJUn5+/vFV3VsYMgIAgHVJfU3T2dmppqYmBQKBgwdwuxUIBNTQ0NDtPn/6059UWlqquXPnyu/3a+rUqbrtttsUjUZ7PE9HR4cikUjCAgAAhqakwsiOHTsUjUbl9/sT1vv9foXD4W732bJli/74xz8qGo1q5cqVuvnmm/XLX/5SP//5z3s8TzAYVGZmZnzJy8tLpsykGQaNAABgTZ8/TROLxTRmzBjdc889KiwsVHl5uW666SbV1dX1uE9NTY3a2triS0tLS1+XCQAALElqzEh2drY8Ho9aW1sT1re2tionJ6fbfcaOHavU1FR5PJ74utNPP13hcFidnZ3yer2H7ePz+eTz+ZIp7ZgwZAQAAPuSujPi9XpVWFioUCgUXxeLxRQKhVRaWtrtPueee67efvttxWKx+Lo333xTY8eO7TaIAAAAZ0n6a5rq6motWbJEv/vd77Rp0yZdc801am9vjz9dM3v2bNXU1MTbX3PNNdq5c6fmzZunN998U0888YRuu+02zZ07t/eu4jgxYgQAAHuSfrS3vLxc27dv1/z58xUOh1VQUKD6+vr4oNbm5ma53QczTl5enp588kn94Ac/0Jlnnqnc3FzNmzdPN9xwQ+9dBQAAGLSSDiOSVFVVpaqqqm63rV69+rB1paWleuGFF47lVH3K5WLUCAAAtvFuGgAAYBVhRLybBgAAmwgjAADAKkeHEUaMAABgn6PDCAAAsI8wIuYZAQDAJsIIAACwytFhhGlGAACwz9FhBAAA2EcYkWSYaAQAAGsIIwAAwCpHhxGGjAAAYJ+jwwgAALCPMAIAAKwijAAAAKscHUZcTDQCAIB1jg4jAADAPsKIJKYZAQDAHsIIAACwytFhhBEjAADY5+gwAgAA7COMSDJi0AgAALYQRgAAgFXODiMMGgEAwDpnhxEAAGAdYUTMMwIAgE2EEQAAYJWjw4iLQSMAAFjn6DACAADsI4xIzDICAIBFjg4jLr6lAQDAOkeHEQAAYB9hRDzaCwCATYQRAABglaPDCENGAACwz9FhBAAA2EcYkWR4uBcAAGuOKYzU1tYqPz9faWlpKikpUWNjY49t77vvPrlcroQlLS3tmAsGAABDS9JhZPny5aqurtaCBQu0du1aTZ8+XWVlZdq2bVuP+2RkZOjDDz+ML++9995xFd1bmGcEAAD7kg4jixYt0pw5c1RZWakpU6aorq5O6enpWrp0aY/7uFwu5eTkxBe/339cRQMAgKEjqTDS2dmppqYmBQKBgwdwuxUIBNTQ0NDjfh9//LFOOukk5eXl6ZJLLtHrr79+xPN0dHQoEokkLH2JeUYAALAnqTCyY8cORaPRw+5s+P1+hcPhbvc57bTTtHTpUj322GN64IEHFIvFdM455+j999/v8TzBYFCZmZnxJS8vL5kyAQDAINLnT9OUlpZq9uzZKigo0IUXXqiHH35YJ554on7961/3uE9NTY3a2triS0tLS5/U5mKmEQAArEtJpnF2drY8Ho9aW1sT1re2tionJ+eojpGamqoZM2bo7bff7rGNz+eTz+dLpjQAADBIJXVnxOv1qrCwUKFQKL4uFospFAqptLT0qI4RjUa1fv16jR07NrlKAQDAkJTUnRFJqq6uVkVFhYqKilRcXKzFixervb1dlZWVkqTZs2crNzdXwWBQknTLLbfo7LPP1sSJE7Vr1y7dcccdeu+993T11Vf37pUAAIBBKekwUl5eru3bt2v+/PkKh8MqKChQfX19fFBrc3Oz3O6DN1w++ugjzZkzR+FwWCNHjlRhYaGef/55TZkypfeu4hgxzwgAAPa5jBn4D7ZGIhFlZmaqra1NGRkZvXbcG//nNS17qUXXl52muV+a2GvHBQAAR//7m3fTSBoEeQwAgCGLMAIAAKxydBhhzAgAAPY5OowAAAD7CCPi3TQAANhEGAEAAFY5PIwwaAQAANscHkYAAIBthBFJDBkBAMAewggAALDK0WGEeUYAALDP0WEEAADYRxgR84wAAGATYQQAAFjl6DDCkBEAAOxzdBgBAAD2EUYkGWYaAQDAGsIIAACwytFhhHlGAACwz9FhBAAA2EcYEfOMAABgE2EEAABY5egw4mKmEQAArHN0GAEAAPYRRiRmGQEAwCLCCAAAsMrRYYR5RgAAsM/RYSSOZ3sBALCGMAIAAKwijAAAAKscHUYYMgIAgH2ODiNdGDECAIA9hBEAAGAVYQQAAFjl6DDiYqIRAACsc3QY6cI0IwAA2EMYAQAAVhFGAACAVccURmpra5Wfn6+0tDSVlJSosbHxqPZbtmyZXC6XLr300mM5LQAAGIKSDiPLly9XdXW1FixYoLVr12r69OkqKyvTtm3bjrjfu+++qx/+8Ic6//zzj7nYvmKYaQQAAGuSDiOLFi3SnDlzVFlZqSlTpqiurk7p6elaunRpj/tEo1HNmjVLP/3pT3XKKaccV8EAAGBoSSqMdHZ2qqmpSYFA4OAB3G4FAgE1NDT0uN8tt9yiMWPG6Kqrrjqq83R0dCgSiSQsAABgaEoqjOzYsUPRaFR+vz9hvd/vVzgc7nafNWvW6N5779WSJUuO+jzBYFCZmZnxJS8vL5kyjxrTjAAAYF+fPk2ze/duXXnllVqyZImys7OPer+amhq1tbXFl5aWlj6sknlGAACwKSWZxtnZ2fJ4PGptbU1Y39raqpycnMPa/9///Z/effddff3rX4+vi8Vin544JUWbN2/Wqaeeeth+Pp9PPp8vmdIAAMAgldSdEa/Xq8LCQoVCofi6WCymUCik0tLSw9pPnjxZ69ev17p16+LLN77xDX3pS1/SunXr+uzrFwAAMHgkdWdEkqqrq1VRUaGioiIVFxdr8eLFam9vV2VlpSRp9uzZys3NVTAYVFpamqZOnZqwf1ZWliQdtt4Glxg0AgCAbUmHkfLycm3fvl3z589XOBxWQUGB6uvr44Nam5ub5XYProldGTICAIA9SYcRSaqqqlJVVVW321avXn3Efe+7775jOSUAABiiBtctDAAAMOQ4OowwzwgAAPY5Oox0YZ4RAADsIYwAAACrCCMAAMAqR4cRhowAAGCfo8NIF8NMIwAAWEMYAQAAVhFGAACAVY4OI8wzAgCAfY4OI3EMGQEAwBrCCAAAsIowAgAArHJ0GHExaAQAAOscHUa6MGQEAAB7CCMAAMAqwggAALDK0WGEESMAANjn6DDSxRhGjQAAYAthBAAAWEUYAQAAVjk7jBwYNMK3NAAA2OPsMAIAAKwjjAAAAKsIIwAAwCpHhxHXgUEjDBkBAMAeR4cRAABgH2EEAABYRRgBAABWOTqMuJhnBAAA6xwdRgAAgH2EEQAAYBVhBAAAWOXoMHJgyIgMM40AAGCNo8MIAACwjzACAACsIowAAACrjimM1NbWKj8/X2lpaSopKVFjY2OPbR9++GEVFRUpKytLJ5xwggoKCnT//fcfc8G9iXlGAACwL+kwsnz5clVXV2vBggVau3atpk+frrKyMm3btq3b9qNGjdJNN92khoYGvfbaa6qsrFRlZaWefPLJ4y4eAAAMfkmHkUWLFmnOnDmqrKzUlClTVFdXp/T0dC1durTb9hdddJG++c1v6vTTT9epp56qefPm6cwzz9SaNWuOu3gAADD4JRVGOjs71dTUpEAgcPAAbrcCgYAaGho+d39jjEKhkDZv3qwLLrigx3YdHR2KRCIJCwAAGJqSCiM7duxQNBqV3+9PWO/3+xUOh3vcr62tTcOHD5fX69XMmTN111136ctf/nKP7YPBoDIzM+NLXl5eMmUeNVd8phEAAGBLvzxNM2LECK1bt04vvfSSbr31VlVXV2v16tU9tq+pqVFbW1t8aWlp6Y8yAQCABSnJNM7OzpbH41Fra2vC+tbWVuXk5PS4n9vt1sSJEyVJBQUF2rRpk4LBoC666KJu2/t8Pvl8vmRKAwAAg1RSd0a8Xq8KCwsVCoXi62KxmEKhkEpLS4/6OLFYTB0dHcmcuk+4+JYGAADrkrozIknV1dWqqKhQUVGRiouLtXjxYrW3t6uyslKSNHv2bOXm5ioYDEr6dPxHUVGRTj31VHV0dGjlypW6//77dffdd/fulRwHw0QjAABYk3QYKS8v1/bt2zV//nyFw2EVFBSovr4+Pqi1ublZbvfBGy7t7e269tpr9f7772vYsGGaPHmyHnjgAZWXl/feVQAAgEHLZQbBbYFIJKLMzEy1tbUpIyOj1477y6c2666n31ZF6Un66SVTe+24AADg6H9/O/rdNAwZAQDAPkeHkS4D/tYQAABDGGEEAABYRRgBAABWOTuMMNEIAADWOTuMHDDwnycCAGDoIowAAACrCCMAAMAqR4cRRowAAGCfo8NIF8NMIwAAWEMYAQAAVhFGAACAVY4OI0wzAgCAfY4OI12YZwQAAHsIIwAAwCrCCAAAsMrRYcR1YKYRvqUBAMAeR4cRAABgH2EEAABYRRgBAABWOTqMdM0zwqO9AADY4+gwAgAA7COMAAAAqwgjAADAKkeHkYOvpmHQCAAAtjg6jAAAAPsIIwAAwCrCCAAAsMrRYYR5RgAAsM/RYQQAANhHGAEAAFYRRgAAgFWODiOuA4NGGDMCAIA9jg4jAADAPsIIAACwijACAACsIoxIMrybBgAAa44pjNTW1io/P19paWkqKSlRY2Njj22XLFmi888/XyNHjtTIkSMVCASO2B4AADhL0mFk+fLlqq6u1oIFC7R27VpNnz5dZWVl2rZtW7ftV69erSuuuELPPPOMGhoalJeXp6985Sv64IMPjrt4AAAw+CUdRhYtWqQ5c+aosrJSU6ZMUV1dndLT07V06dJu2z/44IO69tprVVBQoMmTJ+s3v/mNYrGYQqHQcRcPAAAGv6TCSGdnp5qamhQIBA4ewO1WIBBQQ0PDUR1jz5492rdvn0aNGpVcpX2Ad9MAAGBfSjKNd+zYoWg0Kr/fn7De7/frjTfeOKpj3HDDDRo3blxCoPmsjo4OdXR0xD9HIpFkygQAAINIvz5Ns3DhQi1btkyPPPKI0tLSemwXDAaVmZkZX/Ly8vqxSgAA0J+SCiPZ2dnyeDxqbW1NWN/a2qqcnJwj7nvnnXdq4cKFeuqpp3TmmWcesW1NTY3a2triS0tLSzJlAgCAQSSpMOL1elVYWJgw+LRrMGppaWmP+91+++362c9+pvr6ehUVFX3ueXw+nzIyMhKWvuDSgXfT9MnRAQDA0UhqzIgkVVdXq6KiQkVFRSouLtbixYvV3t6uyspKSdLs2bOVm5urYDAoSfrFL36h+fPn66GHHlJ+fr7C4bAkafjw4Ro+fHgvXgoAABiMkg4j5eXl2r59u+bPn69wOKyCggLV19fHB7U2NzfL7T54w+Xuu+9WZ2en/vEf/zHhOAsWLNC///u/H1/1AABg0Es6jEhSVVWVqqqqut22evXqhM/vvvvusZwCAAA4hKPfTcM8IwAA2OfoMAIAAOwjjAAAAKsIIwAAwCpHh5EDQ0ZkmGkEAABrHB1GAACAfYQRAABgFWFEYj54AAAscnQY6ZpnBAAA2OPoMAIAAOwjjAAAAKsII2LICAAANjk6jLjEoBEAAGxzdBgBAAD2EUYAAIBVhBFJxjBqBAAAWxwdRphnBAAA+xwdRgAAgH2EEQAAYBVhRMwzAgCATYQRAABgFWEEAABYRRgBAABWEUYkMc0IAAD2ODqMuJhoBAAA6xwdRgAAgH2EEQAAYBVhRMwzAgCATY4OI4wYAQDAPkeHEQAAYB9hBAAAWEUYkWSYaAQAAGscHUaYZgQAAPscHUYAAIB9hBEAAGAVYUTMMwIAgE2ODiMMGQEAwD5HhxEAAGDfMYWR2tpa5efnKy0tTSUlJWpsbOyx7euvv65vfetbys/Pl8vl0uLFi4+1VgAAMAQlHUaWL1+u6upqLViwQGvXrtX06dNVVlambdu2ddt+z549OuWUU7Rw4ULl5OQcd8F9gkEjAABYk3QYWbRokebMmaPKykpNmTJFdXV1Sk9P19KlS7ttf9ZZZ+mOO+7Q5ZdfLp/Pd9wF9yYXE40AAGBdUmGks7NTTU1NCgQCBw/gdisQCKihoaHXiuro6FAkEklYAADA0JRUGNmxY4ei0aj8fn/Cer/fr3A43GtFBYNBZWZmxpe8vLxeOzYAABhYBuTTNDU1NWpra4svLS0tfXo+w6ARAACsSUmmcXZ2tjwej1pbWxPWt7a29urgVJ/P1y/jSxgyAgCAfUndGfF6vSosLFQoFIqvi8ViCoVCKi0t7fXiAADA0JfUnRFJqq6uVkVFhYqKilRcXKzFixervb1dlZWVkqTZs2crNzdXwWBQ0qeDXjdu3Bj/+YMPPtC6des0fPhwTZw4sRcvBQAADEZJh5Hy8nJt375d8+fPVzgcVkFBgerr6+ODWpubm+V2H7zhsnXrVs2YMSP++c4779Sdd96pCy+8UKtXrz7+KzgOXY/2RmOMGQEAwJakw4gkVVVVqaqqqtttnw0Y+fn5MmZg/rJPdX8aRvZHB2Z9AAA4wYB8mqa/pHg+vfx93BkBAMAaR4eRVE/XnZGY5UoAAHAuR4eRlANjW/iaBgAAe5wdRrrujMS4MwIAgC2ODiPxr2kYMwIAgDWODiNdX9Ps42saAACscXYYYQArAADWOTuMdA1g5WsaAACscXYYOXBnZB93RgAAsMbRYcTr4dFeAABsc3QYGeb1SJL2dO63XAkAAM7l6DAywvfpq3kin+zX29s+tlwNAADO5OgwMjzt4HsCA4v+MmBf6AcAwFDm6DAyLNWT8LmTgawAAPQ7R4cRl8uV8JkbIwAA9D9Hh5HPuuF/XrNdAgAAjkMYOcRj67baLgEAAMdxfBg5cYTPdgkAADia48PI+JHDbJcAAICjOT6MTB+flfD5V0+/xSO+AAD0I8eHkXkXT0r4fOdTb+q5t/9mqRoAAJzH8WFk5Anew9aFI59YqAQAAGdyfBiRpLPyRyZ8drt6aAgAAHodYUTSTTOnJHx2EUYAAOg3hBFJBXlZCZ8ferHZTiEAADgQYeSAay46Nf7zS+9+pHAb40YAAOgPhJEDLp48JuHzkr9usVQJAADOQhg5oCh/lLKHH3yy5t417ygWY74RAAD6GmHkEE98//yEzxNvWqk9nfstVQMAgDMQRg7hz0jTQ1eXxD/HjLR683aLFQEAMPQRRj7jnInZ+tX/mxH//Otnt2jL9o8tVgQAwNBGGOnG184cp3sripTidunVll26pPY5Pf1Gq+2yAAAYkggjPbj4dL9WVV+oabmZ2v3Jfn3nvpf140fW6+MOxpAAANCbCCNHcHL2CVrxvVJddd7Jkj6dDK3sP57Vc2/vsFwZAABDB2Hkc6SlenTz16booatLNH7kMH2wa69m/eZFXftgk1p27rFdHgAAg57LGDPgJ9OIRCLKzMxUW1ubMjIyrNXR3rFft9e/oftfeE8xI3k9bl1WNF7fveAUnTT6BGt1AQAwEB3t72/CyDF4IxzRzx/fpDUHvq5xu6SyM3J0WdF4XTDpRKV4uOEEAMDR/v4+pt+atbW1ys/PV1pamkpKStTY2HjE9itWrNDkyZOVlpamadOmaeXKlcdy2gFjck6G7r+qWL+fc7YuOu1ExYz05w1hfee+l3V2MKQfrnhVj637QOG2TzQIsh4AAFYlfWdk+fLlmj17turq6lRSUqLFixdrxYoV2rx5s8aMGXNY++eff14XXHCBgsGgvva1r+mhhx7SL37xC61du1ZTp049qnMOtDsjn/VGOKLlL7XoT+u26m/tnQnbRp/g1ZRxGTr1xOEaP3KYxo8cptysdI0e7tWoE7xKS/VYqhoAgL7VZ1/TlJSU6KyzztKvfvUrSVIsFlNeXp7+9V//VTfeeONh7cvLy9Xe3q7HH388vu7ss89WQUGB6urqevVibNsXjemFLX/Tmrd26K9v7dDm1t2Kfs77bYalejQyPVVZ6V4NT0tRutejE7wpGub16ASvR8O8KTrB61FaqkfeFLdSPW6lelzxn70et1JTDqzzdG13K8Xjktvlksftksflktut+OfPrj90ndvlktsluVyufuo1AMBQdbS/v1OSOWhnZ6eamppUU1MTX+d2uxUIBNTQ0NDtPg0NDaqurk5YV1ZWpkcffTSZUw8KqR63zp90os6fdKJqJH2yL6o3W3dr49aI3tu5R+9/tFfvf7RHH3y0Vx/t6dS+qNHefVHtbYtqa9sntstP4HYlhhSXPg0oLpcO+9l94Gfp8HVdbSXJ7ZZc6v4YLlfXOT7dV92s62qrQ9Z3RaZDw9PBdTpkXcKHhHaHtj20XcL+n7P94LrPq6PndoltDz9P9+0O1tRdvQk1J1HH50k2qyZ37OQOnlTrpOs++h2SKTvZqJ/csZPsv2SOnfT/R+mb/kvuyAOo/5I6cv//n8KrzjtZeaPS+/WcXZIKIzt27FA0GpXf709Y7/f79cYbb3S7Tzgc7rZ9OBzu8TwdHR3q6OiIf45EIsmUOWCkpXp05vgsnTk+67Btxhh93LFfH7Xv0849nfpoT6faO/ZrT2dUezr2a8++qPZ2RtXeEdXeffu1tzOqfTGjfftj6ozGtC8a07795uDP0Zg698e0L2rUsT+mmDGKxoxiMaNo18/xPz+/9piRYlEjiTEvAOAE3ygYNzjCSH8JBoP66U9/aruMPuVyuTQiLVUj0lI1YXT//uUb82kgiX02pMR0WHDp+tmYT2NJ177Soet0SJtP/5R02H7xPw/Zr+t4Rp+uTDjeIfvJdH88HWh/yNUdtu7QzV3rzSFrD65L7KPD++3QY3Zznm7OeehxzGE/HE0dPbdLPGY35zl0/26299RHR6OvB2Yne3iT5BUkf/wk2w+w+pOV7N+v0/oz6e5Ptj/79vA9yslI650DHYOkwkh2drY8Ho9aWxPf09La2qqcnJxu98nJyUmqvSTV1NQkfLUTiUSUl5eXTKk4ApfLJY9L8sglxs8CAGxL6tFer9erwsJChUKh+LpYLKZQKKTS0tJu9yktLU1oL0mrVq3qsb0k+Xw+ZWRkJCwAAGBoSvprmurqalVUVKioqEjFxcVavHix2tvbVVlZKUmaPXu2cnNzFQwGJUnz5s3ThRdeqF/+8peaOXOmli1bppdffln33HNP714JAAAYlJIOI+Xl5dq+fbvmz5+vcDisgoIC1dfXxwepNjc3y+0+eMPlnHPO0UMPPaSf/OQn+vGPf6xJkybp0UcfPeo5RgAAwNDGdPAAAKBP9Ol08AAAAL2FMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwKunp4G3omiQ2EolYrgQAABytrt/bnzfZ+6AII7t375Yk5eXlWa4EAAAka/fu3crMzOxx+6B4N00sFtPWrVs1YsQIuVyuXjtuJBJRXl6eWlpaeOdNH6Kf+w993T/o5/5BP/ePvuxnY4x2796tcePGJbxE97MGxZ0Rt9ut8ePH99nxMzIy+B96P6Cf+w993T/o5/5BP/ePvurnI90R6cIAVgAAYBVhBAAAWOXoMOLz+bRgwQL5fD7bpQxp9HP/oa/7B/3cP+jn/jEQ+nlQDGAFAABDl6PvjAAAAPsIIwAAwCrCCAAAsIowAgAArHJ0GKmtrVV+fr7S0tJUUlKixsZG2yUNWMFgUGeddZZGjBihMWPG6NJLL9XmzZsT2nzyySeaO3euRo8ereHDh+tb3/qWWltbE9o0Nzdr5syZSk9P15gxY3T99ddr//79CW1Wr16tL37xi/L5fJo4caLuu+++vr68AWvhwoVyuVy67rrr4uvo597xwQcf6Nvf/rZGjx6tYcOGadq0aXr55Zfj240xmj9/vsaOHathw4YpEAjorbfeSjjGzp07NWvWLGVkZCgrK0tXXXWVPv7444Q2r732ms4//3ylpaUpLy9Pt99+e79c30AQjUZ188036+STT9awYcN06qmn6mc/+1nCe0ro52Pz7LPP6utf/7rGjRsnl8ulRx99NGF7f/brihUrNHnyZKWlpWnatGlauXJl8hdkHGrZsmXG6/WapUuXmtdff93MmTPHZGVlmdbWVtulDUhlZWXmt7/9rdmwYYNZt26d+fu//3szYcIE8/HHH8fbfO973zN5eXkmFAqZl19+2Zx99tnmnHPOiW/fv3+/mTp1qgkEAuaVV14xK1euNNnZ2aampibeZsuWLSY9Pd1UV1ebjRs3mrvuust4PB5TX1/fr9c7EDQ2Npr8/Hxz5plnmnnz5sXX08/Hb+fOneakk04y//zP/2xefPFFs2XLFvPkk0+at99+O95m4cKFJjMz0zz66KPm1VdfNd/4xjfMySefbPbu3Rtv83d/93dm+vTp5oUXXjB//etfzcSJE80VV1wR397W1mb8fr+ZNWuW2bBhg/n9739vhg0bZn7961/36/Xacuutt5rRo0ebxx9/3LzzzjtmxYoVZvjw4eY///M/423o52OzcuVKc9NNN5mHH37YSDKPPPJIwvb+6tfnnnvOeDwec/vtt5uNGzean/zkJyY1NdWsX78+qetxbBgpLi42c+fOjX+ORqNm3LhxJhgMWqxq8Ni2bZuRZP7yl78YY4zZtWuXSU1NNStWrIi32bRpk5FkGhoajDGf/sfjdrtNOByOt7n77rtNRkaG6ejoMMYY86Mf/cicccYZCecqLy83ZWVlfX1JA8ru3bvNpEmTzKpVq8yFF14YDyP0c++44YYbzHnnndfj9lgsZnJycswdd9wRX7dr1y7j8/nM73//e2OMMRs3bjSSzEsvvRRv8+c//9m4XC7zwQcfGGOM+e///m8zcuTIeL93nfu0007r7UsakGbOnGm+853vJKz7h3/4BzNr1ixjDP3cWz4bRvqzX//pn/7JzJw5M6GekpIS8y//8i9JXYMjv6bp7OxUU1OTAoFAfJ3b7VYgEFBDQ4PFygaPtrY2SdKoUaMkSU1NTdq3b19Cn06ePFkTJkyI92lDQ4OmTZsmv98fb1NWVqZIJKLXX3893ubQY3S1cdrfy9y5czVz5szD+oJ+7h1/+tOfVFRUpMsuu0xjxozRjBkztGTJkvj2d955R+FwOKGPMjMzVVJSktDPWVlZKioqircJBAJyu9168cUX420uuOACeb3eeJuysjJt3rxZH330UV9fpnXnnHOOQqGQ3nzzTUnSq6++qjVr1uirX/2qJPq5r/Rnv/bWvyWODCM7duxQNBpN+Mdakvx+v8LhsKWqBo9YLKbrrrtO5557rqZOnSpJCofD8nq9ysrKSmh7aJ+Gw+Fu+7xr25HaRCIR7d27ty8uZ8BZtmyZ1q5dq2AweNg2+rl3bNmyRXfffbcmTZqkJ598Utdcc42+//3v63e/+52kg/10pH8jwuGwxowZk7A9JSVFo0aNSurvYii78cYbdfnll2vy5MlKTU3VjBkzdN1112nWrFmS6Oe+0p/92lObZPt9ULy1FwPL3LlztWHDBq1Zs8Z2KUNOS0uL5s2bp1WrViktLc12OUNWLBZTUVGRbrvtNknSjBkztGHDBtXV1amiosJydUPHH/7wBz344IN66KGHdMYZZ2jdunW67rrrNG7cOPoZCRx5ZyQ7O1sej+ewJxBaW1uVk5NjqarBoaqqSo8//rieeeYZjR8/Pr4+JydHnZ2d2rVrV0L7Q/s0Jyen2z7v2nakNhkZGRo2bFhvX86A09TUpG3btumLX/yiUlJSlJKSor/85S/6r//6L6WkpMjv99PPvWDs2LGaMmVKwrrTTz9dzc3Nkg7205H+jcjJydG2bdsStu/fv187d+5M6u9iKLv++uvjd0emTZumK6+8Uj/4wQ/id/3o577Rn/3aU5tk+92RYcTr9aqwsFChUCi+LhaLKRQKqbS01GJlA5cxRlVVVXrkkUf09NNP6+STT07YXlhYqNTU1IQ+3bx5s5qbm+N9WlpaqvXr1yf8B7Bq1SplZGTEfzGUlpYmHKOrjVP+Xi6++GKtX79e69atiy9FRUWaNWtW/Gf6+fide+65hz2a/uabb+qkk06SJJ188snKyclJ6KNIJKIXX3wxoZ937dqlpqameJunn35asVhMJSUl8TbPPvus9u3bF2+zatUqnXbaaRo5cmSfXd9AsWfPHrndib9mPB6PYrGYJPq5r/Rnv/bavyVJDXcdQpYtW2Z8Pp+57777zMaNG813v/tdk5WVlfAEAg665pprTGZmplm9erX58MMP48uePXvibb73ve+ZCRMmmKefftq8/PLLprS01JSWlsa3dz1y+pWvfMWsW7fO1NfXmxNPPLHbR06vv/56s2nTJlNbW+uoR067c+jTNMbQz72hsbHRpKSkmFtvvdW89dZb5sEHHzTp6enmgQceiLdZuHChycrKMo899ph57bXXzCWXXNLto5EzZswwL774olmzZo2ZNGlSwqORu3btMn6/31x55ZVmw4YNZtmyZSY9PX1IP3J6qIqKCpObmxt/tPfhhx822dnZ5kc/+lG8Df18bHbv3m1eeeUV88orrxhJZtGiReaVV14x7733njGm//r1ueeeMykpKebOO+80mzZtMgsWLODR3mTdddddZsKECcbr9Zri4mLzwgsv2C5pwJLU7fLb3/423mbv3r3m2muvNSNHjjTp6enmm9/8pvnwww8TjvPuu++ar371q2bYsGEmOzvb/Nu//ZvZt29fQptnnnnGFBQUGK/Xa0455ZSEczjRZ8MI/dw7/vd//9dMnTrV+Hw+M3nyZHPPPfckbI/FYubmm282fr/f+Hw+c/HFF5vNmzcntPnb3/5mrrjiCjN8+HCTkZFhKisrze7duxPavPrqq+a8884zPp/P5ObmmoULF/b5tQ0UkUjEzJs3z0yYMMGkpaWZU045xdx0000Jj4rSz8fmmWee6fbf5IqKCmNM//brH/7wB/OFL3zBeL1ec8YZZ5gnnngi6etxGXPIVHgAAAD9zJFjRgAAwMBBGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGDV/wcBbYqtIamg2gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Model Performance\n",
        "At the end I have calculated some useful metrics to evaluate this model.\n",
        "\n",
        "### Accuracy\n",
        "Accuracy is calculated by the ratio between correctly assigned labels and total labels. It may not be the best metric in case of unbalanced dataset.\n",
        "\n",
        "### F1 score\n",
        "The F1 score is calculated as the harmonic mean of Recall and Precision:\n",
        "  $$Recall(r) = \\frac{TP}{TP + FN} \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: Precision(p) = \\frac{TP}{TP + FP}$$\n",
        "<br>\n",
        "  $$F1 \\: score = \\frac{2rp}{r + p}$$\n",
        "\n",
        "- **High Accuracy**: 96.49%, indicating strong generalization.\n",
        "- **High F1 Score**: 97.14%, reflecting excellent balance between precision and recall.\n",
        "\n",
        "The model shows robust performance, making it reliable for accurate predictions on new data."
      ],
      "metadata": {
        "id": "zesN6zupL-42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = nn_model.score(X = X_test_scaled, Y = y_test)\n",
        "f1 = f1_score(y_test, nn_model.predict(X_test_scaled), average='micro')\n",
        "\n",
        "print(f\"Accuracy: {acc * 100:.2f}% ({acc:.4f})\")\n",
        "print(f\"F1 Score (micro-average): {f1 * 100:.2f}% ({f1:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO8A72iayk_D",
        "outputId": "b1e7913b-f647-46c6-8488-f1ac03f0cfa7"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.49% (0.9649)\n",
            "F1 Score (micro-average): 97.14% (0.9714)\n"
          ]
        }
      ]
    }
  ]
}